# Titanic-Exploratory-Data-Analysis-Data-Preprocessing

This project covers exploratory data analysis (EDA) and data preparation processes by examining whether passengers survived during the Titanic disaster. The aim is to analyze the features in the dataset, clean, transform and make the data suitable for machine learning models. The project includes steps such as data visualization and feature engineering to understand the factors that affect the probability of passengers surviving the Titanic disaster.

The dataset used in the project is the Kaggle Titanic dataset. This dataset includes various features (age, gender, ticket class, etc.) of passengers traveling on the Titanic. Information such as the passengers' ID numbers, survival status, ticket classes, ages and the port they boarded the ship were analyzed. Columns with missing values ​​such as age and cabin were filled in appropriately or were not processed. Categorical variables such as gender and ticket class were converted to numerical data using the one-hot encoding method.

Seaborn and Matplotlib libraries were used in the data visualization phase of the project. Thanks to these visualizations, the relationships between the passengers' characteristics such as age, gender and ticket class and their survival status were analyzed. Age distribution and survival rates were examined, and especially the effects of gender and ticket class on survival were shown with graphs. These visualizations helped to better understand the important trends and correlations in the dataset.

In the data transformation and feature engineering stages, standardization of numerical data was performed and logarithmic transformations were applied. The skewness in the distributions of variables such as ticket fare was corrected with logarithmic transformation. In addition, new features were derived from existing variables and interaction terms were created (e.g. Fare * Age). These steps made the dataset more suitable for machine learning algorithms.

Python libraries used in the project include pandas, numpy, seaborn, matplotlib and scikit-learn. The following command can be used to ensure that these libraries are installed: pip install pandas numpy seaborn matplotlib scikit-learn. The project is designed to be run in Jupyter Notebook or Python environments. To start the project, you first need to clone this repository to your computer, install the necessary libraries, and then run the notebook file.

Finally, this project focuses on data preparation and analysis stages. With future improvements, predictions can be made using different machine learning models. Modeling can be done with algorithms such as Logistic Regression, Decision Trees, or Random Forest, and model performance can be evaluated using various metrics.
